\section{Ansätze}
% Welche klassischen, Deep Learning -, und eigenen Ansätze wurde verwendet?
% Kurze Beschreibung neuer Techniken und Ideen

\subsection{Klassische Ansätze}

Als klassische Ansätze zur Stimmungsanalyse von Tweets wurden folgende überwachten Lernverfahren ausgewählt, weil diese besonders häufig in der Literatur zu finden sind \cite{wankhade2022survey, medhat2014sentiment, zimbra2018state}:

\begin{itemize}
    \item Logistische Regression
    \item \gls{svm}
    \item Naiver Bayes Klassifikator
\end{itemize}

\redhl{TODO: Ggf. Anmerkung ergänzen, dass zwei weitere klassische Ansätze evaluiert wurden.}

\subsubsection{Logistische Regression}

Die logistische Regression ist ein Verfahren zur Klassifikation, das auf der Sigmoid-Funktion basiert. Diese Funktion ist definiert als:

\begin{equation*}
    \sigma(z) = \frac{1}{1 + e^{-z}}
\end{equation*}

wodurch Werte aus dem gesamten Zahlenraum auf das Intervall $(0,1)$ abgebildet werden. Die Entscheidungsregel für einen Datenpunkt $x$ ergibt sich durch:

\begin{equation*}
    h_{\theta}(x) = \sigma(\theta \cdot x + b), \text{ wobei } \theta \in \mathbb{R}^{n}, b \in \mathbb{R}
\end{equation*}

Ein Datenpunkt wird dabei der Klasse 1 zugeordnet, wenn $h_{\theta}(x) \geq 0.5$, ansonsten der Klasse 0:

\begin{equation*}
    clf_{\theta, b}(x) =
    \begin{cases}
        1, & \text{wenn } h_{\theta}(x) \geq 0.5 \\
        0, & \text{sonst}
    \end{cases}
\end{equation*}

Zur Bestimmung der Parameter $\theta$ und $b$ wird die logistische Verlustfunktion minimiert:

\begin{equation*}
    \min_{\theta, b} \frac{1}{m} \sum_{i=1}^{m} \left[-y_i \log h_{\theta}(x_i) - (1 - y_i) \log(1 - h_{\theta}(x_i))\right]
\end{equation*}

Dieses Optimierungsproblem ist konvex und wird mithilfe des \textit{Gradient Descent} gelöst. Dabei werden die Parameter iterativ durch:

\begin{equation*}
    \theta \leftarrow \theta - \alpha \nabla_{\theta} L
\end{equation*}

aktualisiert, wobei $\alpha > 0$ die Lernrate ist. Eine Regularisierung kann durch einen zusätzlichen Term $\lambda \lVert\theta\rVert^2$ eingeführt werden, um Überanpassung zu vermeiden.

\subsubsection{\textit{Support Vector Machine}}

Die \gls{svm} wird oftmals zur Klassifikation verwendet.
Die Klassifikation erfolgt dabei durch die Bestimmung einer Hyperebene, die die Daten in zwei Klassen trennt.
Eine Hyperebene in $\mathbb{R}^{n}$ ist definiert als die Menge aller Punkte $x\in\mathbb{R}^n$ für die gilt:
\begin{equation*}
    \theta \cdot x - b = 0, \text{ wobei } \theta \in \mathbb{R}^{n}, b\in\mathbb{R}
\end{equation*}

Für linear nicht separierbare Datensätze, lässt sich keine Hyperebene finden, die die Daten perfekt trennt.
Stattdessen wird versucht eine Hyperebene zu bestimmen, die die Daten unter Berücksichtigung der \textit{Hinge}-Fehlerfunktion\footnote{
    Die \textit{Hinge}-Fehlerfunktion ist definiert als:
    \begin{equation*}
        L^{hinge}(D, \theta, b) = \sum_{1}^{m}\max\lbrace0, 1 - y_i(\theta \cdot x_i - b)\rbrace
    \end{equation*}
} möglichst gut trennt.
Die optimalen Parameter zur Bestimmung der Hyperebene können durch folgendes Minimierungsproblem, für einen Regularisierungsparameter $C\geq0$, bestimmt werden:
\begin{equation*}
    \min_{w, b} \lvert\lvert \theta \rvert\rvert + C \frac{1}{m}\sum_{i=1}^{m} \max\lbrace0, 1 - y_i(\theta \cdot x_i - b)\rbrace
\end{equation*}

Die binäre Klassifikation von Datenpunkten erfolgt dann durch die Bestimmung der Klasse des Datenpunktes $x$ durch:
\begin{equation*}
    clf_{\theta, b}(x) =
    \begin{cases}
        1, & \text{wenn } \theta \cdot x - b \geq 0 \\
        -1, & \text{sonst}
    \end{cases}
\end{equation*}

\subsubsection{Naiver Bayes Klassifikator}
Der \textit{naive Bayes-Klassifikator}, benannt nach dem englischen Mathematiker Thomas Bayes, ist ein maschinelles Lernverfahren, das aufgrund seiner Einfachheit und Effizienz häufig für Klassifikationsprobleme eingesetzt wird \cite{wankhade2022survey, medhat2014sentiment, zimbra2018state}.

Das Ziel ist es, für einen \textit{Trainingsdatensatz} $D$ eine optimale \textit{Hypothese} $h$ zu finden. Das Verfahren basiert auf dem \textit{Bayes-Theorem}, welches uns ermöglicht, uns der gesuchten optimalen Wahrscheinlichkeit $P(h|D)$ anzunähern. Dabei ist $P(h|D)$ die Wahrscheinlichkeit von $h$, gegeben der Beobachtung $D$:

\begin{equation*}
    P(h|D) = \frac{P(D|h)P(h)}{P(D)}
\end{equation*}

Wir suchen also eine Hypothese $h^*$ die den Wert $P(h|D)$ maximiert:
\begin{equation*}
    h^* = \arg\max_{h} P(h|D)
\end{equation*}

Die Grundidee des naiven Bayes-Klassifikators ist die Annahme, dass die einzelnen Merkmale unabhängig voneinander sind.

Sei $D = (x^{(1)}, y^{(1)}), \dots, (x^{(m)}, y^{(m)})$ ein Datensatz, $c$ eine Klasse im Merkmalsraum $Z$  und $x=(x_1, \dots,x_n)\in Z_1 \times \dots \times Z_n$ ein neuer Datenpunkt. Dann ist der Naive-Bayes-Klassifikator
\begin{equation*}
    clf_D^{NaiveBayes}(x) = \arg \max_{c\in Z} P(c|D)P(x_1|c,D)P(x_2|c,D) \dots P(x_n|c,D)
\end{equation*}
mit
\begin{equation*}
    P(c|D) = \frac{|\{(z,c)\in D\}|}{|D|}
\end{equation*}
\begin{equation*}
    P(x_i|c,D) = \frac{|\{(z^\prime,c)\in D| z^\prime = (z_1, \dots, z_n), z_i=x_i \}|}{|\{(z,c)\in D\}|} \quad \text{für} \: i = 1, \dots, n
\end{equation*}

Trotz der naiven Unabhängigkeitsannahme führt dieses Verfahren in der Praxis für eine Vielzahl von Anwendungsfällen zu guten Ergebnissen \cite{hand2001idiot}. Der naive Bayes-Klassifikator wird daher neben der Sentimentanalyse häufig auch für andere Textklassifikationsaufgaben eingesetzt. Eine typische Anwendung ist z.B. die Spam-Filterung \cite{sahami1998bayesian}.

\subsection{Deep Learning Ansätze}
Als Deep Learning Ansätze haben wir zuerst zwei auf \gls{bert} \cite{devlin2018bert} basierende Modelle ausgewählt, welche wir durch \textit{Finetuning} mit dem Datensatz sentiment140 trainiert haben. 
Zum einen das auf Twitter-Daten vortrainierte Modell RoBERTa \cite{liu2019roberta} und zum anderen das von \gls{bert} destillierte Modell DistillBert \cite{sanh2019distilbert}. 
BERT-Modelle basieren auf der von Vaswani et al. beschriebenen Architektur \textit{Multi-layer Bidirectional Transformer Encoder} \cite{vaswani2017attention}. 
\subsubsection{Transformer}
Die Architektur eines \textit{Multi-layer Bidirectional Transformer Encoder} besteht aus einen \textit{Encoder}, der eine Eingabe von Symbolen $(x_1,...,x_n)$ auf eine kontinuierliche Repräsentation $(z_1,...,z_n)$ abbildet 
und einem \textit{Decoder}, der aus dieser kontinuierlichen Repräsentation eine Ausgabesequenz aus Symbolen $(y_1,...,y_n)$ generiert. Für jedem Schritt verwendet der 
\textit{Decoder} seine Ausgabe aus dem vorherigen Schritt. \par
%Bild Transformer?
\textit{Encoder} besteht aus $N$ gleichen Schichten, die jeweils aus einem \textit{Multi-head Self-Attention}-Mechanismus und einem vollvernetzten Neuronalen Netz bestehen.
Der \textit{Decoder} besteht aus $N$ gleichen Schichten, bestehend aus einer Schicht \textit{Multi-head Self-Attention} und einem vollvernetzten Neuronalen Netz. zusätzlich kommt eine weitere Schicht \textit{Multi-head Self-Attention},
welche die Ausgabe des \textit{Encoders} verarbeitet. \par
Der \textit{Attention}-Mechanismus \cite{vaswani2017attention} bildet ein \textit{Query} und eine Menge von Schlüssel-Wert-Paaren auf eine Ausgabe ab. Alle Bestandteile sind Vektoren.
%Bild Scaled Dot-Product Attention?
Die von Vaswani et al. verwendete \textit{Attention}-Funktion ist die sogenannte \textit{Scaled Dot-Product Attention}. Die Eingabe besteht aus \textit{Queries} und Schlüsseln mit der Dimension $d_k$ und Werten mit der Dimension $d_v$.
Zuerst wird das innere Produkt aus \textit{Queries} und Schlüsseln berechnet danach wird das Produkt durch $\sqrt{d_k}$ geteilt, also skaliert. Im nächsten Schritt wird von dem Ergebnis die \textit{Softmax}-Funktion berechnet, um die Gewichte zu erhalten, mit denen die Werte multipliziert werden. 
In der Praxis werden mehrere \textit{Queries} parallel berechnet, indem sie in einer Matrix $Q$ zusammengefasst werden. Ebenso werden die Schlüssel in Matrix $K$ und die Werte in Matrix $V$ zusammengefasst.
Daraus ergibt sich für die \textit{Attention}-Funktion folgende Formel:
\begin{equation*}
Attention(Q,K,V) = softmax(\frac{QK^T}{\sqrt{d_k}})V    
\end{equation*}
Der \textit{Multi-head Attention}-Mechanismus erweitert dies um \textit{h} erlernte lineare Projektionen der einzelnen $d_{model}$-dimensionalen Vektoren auf die Dimensionen $d_k$, $d_k$ und $d_v$. 
Diese parallel berechneten Werte werden konkateniert und ein weiteres mal linear projiziert, um die Ausgabe der \textit{Multi-head Attention} zu erhalten.
\begin{align*}
   & \mathrm{MultiHead}(Q,K,V) = \mathrm{Concat}(\mathrm{head_1},...,\mathrm{head_h})W^O \\
   & \mathrm{where} \quad \mathrm{head_i} = \mathrm{Attention}(QW_i^Q,KW_i^K,VW_i^V)
\end{align*}
Die Projektionen sind Gewichtsmatrizen $W_i^Q \in \mathbb{R}^{d_{model}\times d_k}$, $W_i^K \in \mathbb{R}^{d_{model}\times d_k}$, $W_i^V \in \mathbb{R}^{d_{model}\times d_v}$ und $W^O \in \mathbb{R}^{hd_v\times d_{model}}$
\subsubsection{Finetuning}
\section{Ausblick}\label{sec:ausblick}

Es gibt mehrere Ansätze, um die Vorgehensweise und die Ergebnisse der Stimmungsanalyse zu optimieren.

\subsection{\textit{Noisy Labels}}
Wie in Abschnitt \ref{subsec:trainingsdatensatz} beschrieben, führt die Art, wie der Trainingsdatensatz \textit{Sentiment140} erstellt wurde, zu \textit{Noisy Labels}.
Dies kann bei der Verwendung einfacherer Modelle zu schlechteren Klassifikationsergebnissen führen und die Anzahl der benötigten Trainingsbeispiele oder die Komplexität der Modelle erhöhen \cite{NoisyLabel2014}.
Die erzielten Genauigkeiten der klassischen Ansätze (bis zu 85\%) und die Ergebnisse von  Go et al. ($79-83\%$, vgl. Tabelle 6 in \cite{go2009twitter}) bestätigen diese Aussage.

Um den Effekt von \textit{Noisy Labels} zu verringern, können robustere Modelle oder Methoden der Datenbereinigung verwendet werden, also Datensätze entfernt oder sogenannte semi-überwachte Lernverfahren angewendet werden. Alternativ können auch tolerante Lernverfahren angewandt werden (vgl. Abschnitt 3 in \cite{NoisyLabel2014}).

Eine grundsätzlich andere Herangehensweise ist die Verwendung eines Datensatzes mit höherer Datenqualität, um \textit{Noisy Labels} zu vermeiden.

\subsection{\textit{Aspect Based Sentiment Analysis}}

Die erlangten Ergebnisse der unterschiedlichen Modelle können durch die Verwendung zusätzlicher Informationen verbessert werden, wie die Ergebnisse der Experimente mit den \textit{DeepSeek}-basierten Modellen zeigen.

Bei der \textit{Aspect Based Sentiment Analysis} werden explizite oder implizite Begriffe (\textit{aspects}) aus dem Tweet extrahiert und die Stimmung des Tweets bezüglich dieser Begriffe klassifiziert \cite{Hua_2024}.

Ein Beispiel aus \cite{Hua_2024} zeigt, dass der Satz \glqq \textit{The restaurant was expensive, but the menu was great.}\grqq{} bezüglich dem expliziten Begriff \textit{menu} positiv und bezüglich dem impliziten Begriff \textit{price} negativ klassifiziert wird.

\subsection{Große \textit{Deep Learning} Modelle}

Das \textit{Finetuning} der größeren \textit{DeepSeek}-Modelle mit dem \textit{Sentiment140}-Datensatz stieß auf Rechenkapazitätsgrenzen.

Mehr Rechenkapazitäten oder Methoden wie die \textit{Low Rank Adaptation} (LoRA) \cite{lora2021}, bei der nur eine kleine Anzahl neuer Parameter zur Feinabstimmung genutzt wird, könnten hier Abhilfe schaffen.

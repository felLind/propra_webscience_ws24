\documentclass[researchlab,group,]{AIGpaper}

%%%% Package Imports %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{graphicx}					    % enhanced support for graphics
\usepackage{tabularx}				      	% more flexible tabular
\usepackage{amsfonts}					    % math fonts
\usepackage{amssymb}					    % math symbols
\usepackage{amsmath}					    % overall enhancements to math environment
\usepackage{multirow}					    % multirow for tables
\usepackage{booktabs}					    % improved table design

%%%% optional packages
\usepackage{tikz}                           % creating graphs and other structures
\usepackage{glossaries}                     % glossaries package for glossary entries
\usepackage{soul}                           % for highlighting text (temporary usage)
\usepackage{algorithm}                      % for creating pseudo-code
\usepackage{algpseudocode}                  % for creating pseudo-code
\usepackage{multicol}                       % for creating multi-column environments
\usepackage{enumitem}                       % for reducing space in lists
\usepackage{hyphenat}                       % for hyphenation
\usepackage[hidelinks]{hyperref} % or \usepackage{hyperref}


\setlist{noitemsep}

\newcommand{\redhl}{\sethlcolor{red}\hl}
\newcommand{\greyhl}{\sethlcolor{lightgray}\hl}


%%%% Author and Title Information %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\author{Anne Huber, Andreas Franke, Felix Lindner, Burak Özkan, Milomir Soknic}

\title{Stimmungsanalyse mit Twitter}

%%%% Glossary %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newacronym{bert}{BERT}{\textit{Bidirectional Encoder Representations from Transformers}}
\newacronym{cnn}{CNN}{\textit{Convolutional Neural Network}}
\newacronym{cl}{CL}{Computerlinguistik}
\newacronym{dl}{DL}{\textit{Deep Learning}}
\newacronym{knn}{KNN}{\textit{k-Nearest Neighbors}}
\newacronym{llm}{LLM}{\textit{Large Language Model}}
\newacronym{lr}{LR}{Logistische Regression}
\newacronym{lstm}{LSTM}{\textit{Long Short-Term Memory}}
\newacronym{ml}{ML}{Maschinelles Lernen}
\newacronym{nb}{NB}{Naive Bayes}
\newacronym{nlp}{NLP}{\textit{Natural Language Processing}}
\newacronym{nltk}{NLTK}{\textit{Natural Language Toolkit}}
\newacronym{roberta}{RoBERTa}{\textit{Robustly optimized BERT approach}}
\newacronym{sgd}{SGD}{\textit{Stochastic Gradient Descent}}
\newacronym{svm}{SVM}{\textit{Support Vector Machine}}
\newacronym{tfidf}{TF-IDF}{\textit{Term Frequency-Inverse Document Frequency}}

%%%% Abstract %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\germanabstract{
    Dieser Bericht beschreibt die Durchführung und Ergebnisse eines Projekts zur Stimmungsanalyse von Tweets.
    Ziel des Projekts war es, die Effektivität verschiedener maschineller Lernverfahren, einschließlich klassischer Methoden und Deep-Learning-Ansätze, bei der Klassifizierung der Stimmung von Tweets zu untersuchen.
    Dazu wurden verschiedene Vorverarbeitungsschritte und Vektorisierungsverfahren für klassische Methoden angwendet und evaluiert.
    Für die Deep-Learning Ansätze wurden \textit{Finetuning} Ansätze für \textit{BERT}-basierte Modelle und \textit{DeepSeek}-R1 basierte Modelle verwendet. Des Weiteren wurde ein aspekt-basierter Ansatz mit den \textit{DeepSeek}-R1 basierten Modellen untersucht.
    Die Ergebnisse zeigen, dass Deep-Learning-Modelle, insbesondere fein-abgestimmte \textit{BERT}-basierte Modelle sowie aktuelle \textit{LLMs}, eine höhere Genauigkeit bei der Stimmungsanalyse erzielen als klassische maschinelle Lernverfahren.
}


\begin{document}

\maketitle % prints title and author information, as well as the abstract


% ===================== Beginning of the actual text section =====================

\input{1-einleitung}

\input{2-aufgabenverteilung}

\input{3-teaminterne-organisation}

\input{4-datensaetze-und-problemstellung}

\input{5-ansaetze}

\input{6-experimente}

\input{7-ausblick}

\input{8-zusammenfassung-und-fazit}

% References
\newpage
\addreferences

\makestatement{5}

% ==== Appendix ====
\appendix

\input{9-appendix}



\end{document}

\section{Teaminterne Organisation}\label{sec:teaminterneorganisation}

Zur asynchronen Kommunikation der Projektmitglieder wurde eine private Lerngruppe in einer Discord-Instanz der Studenten der FernUniversität Hagen eingerichtet.
Dort wurden auch die regelmäßigen Treffen über die vorhandenen Sprachkanäle durchgeführt.
Die Intervalle der Treffen wurden in Absprache mit allen Mitgliedern und in Abhängigkeit von den durchgeführten Schritten festgelegt.
In den Treffen wurden die erreichten Ergebnisse besprochen sowie mögliche nächste Schritte diskutiert und geplant.

Als Programmiersprache wurde Python gewählt, da bei allen Projektmitgliedern unter anderem durch die vorherige Teilnahme am Modul \textit{Einführung in Maschinelles Lernen} diesbezüglich Vorkenntnisse vorhanden waren und viele Bibliotheken für \gls{ml} und \gls{dl} in Python verfügbar sind.
Zur Verwaltung der verwendeten Python-Pakete und zur Vereinheitlichung und Prüfung der erstellten Dateien wurden \textit{Poetry} \cite{poetry2025} sowie \textit{pre-commit} \cite{precommit2025} verwendet.

Für die klassischen \gls{ml}-Ansätze wurde insbesondere die Bibliothek \textit{scikit-learn} eingesetzt.
Darüber hinaus wurde für die Anwendung der \gls{dl}-Ansätze und der eigenen Ansätze die \textit{transformers}-Bibliothek von \textit{Hugging Face} genutzt.

Zur Verwaltung der Projektdateien und der gemeinsamen Arbeit wurde ein \textit{GitHub Repository} \cite{githubrepo2025} eingerichtet.
Für neue Ansätze und Ergebnisse sowie Änderungen an Code und Dokumenten wurden in \textit{GitHub} \textit{Branches} angelegt und über \textit{Pull-Requests} überprüft und diskutiert.

Die Abfolge der einzelnen Projektschritte orientierte sich an dem \textit{Data Science Life Cycle} \cite[Abb. 2]{Stodden2020}.
Dieser wurde während der Anwendung der klassischen Ansätze einmal durchlaufen.
Dies beinhaltet die wiederholte Durchführung von Schritten, wie \textit{Obtain Data} und \textit{Data Exploration} oder die parallele Ausführung von \textit{Data Preparation} und \textit{Model Estimation} bei der Durchführung der unterschiedlichen klassischen Ansätze.
Im Anschluss, bei der Anwendung der \gls{dl}-Modelle, wurde gleichermaßen mehrfach über gewisse Schritte des \textit{Data Science Life Cycle} iteriert.

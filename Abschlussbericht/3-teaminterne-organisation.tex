\section{Teaminterne Organisation}\label{sec:teaminterneorganisation}
% Wie wurde innerhalb des Teams kommuniziert?
% Welche Programmiersprache? Warum?
% Welche Tools/Techniken wurden verwendet?
% etc.

Zur asynchronen Kommunikation der Projektmitglieder wurde eine private Lerngruppe in einer Discord-Instanz der Studenten der FernUniversität Hagen eingerichtet.
Dort wurden auch die regelmäßigen Treffen über die vorhandenen Sprachkanäle durchgeführt.
Die Intervalle der Treffen wurden in Absprache mit allen Mitgliedern und in Abhängigkeit von den durchgeführten Schritten festgelegt.
In den Treffen wurden die erreichten Ergebnisse besprochen sowie mögliche nächste Schritte diskutiert und geplant.

Als Programmiersprache wurde \textit{Python} gewählt, da bei allen Projektmitgliedern unter anderem durch die vorherige Teilnahme am Modul \textit{Einführung in Maschinelles Lernen} Vorkenntnisse vorhanden waren und viele Bibliotheken für maschinelles Lernen und \textit{Deep Learning} in \textit{Python} verfügbar sind.
Zur Verwaltung der verwendeten Python-Pakete und zur Vereinheitlichung und Prüfung der erstellten Dateien wurde \textit{Poetry} \cite{poetry2025} sowie \textit{pre-commit}\cite{precommit2025} verwendet.

Für die klassischen \gls{ml}-Verfahren wurde insbesondere die Bibliothek \textit{scikit-learn} eingesetzt.
Darüber hinaus wurde für die Anwendung der \gls{dl} Ansätze und die eigenen Ansätze die \textit{transformers} Bibliothek von \textit{Hugging Face} genutzt.

Zur Verwaltung der Projektdateien und der gemeinsamen Arbeit wurde ein \textit{GitHub Repository} \cite{githubrepo2025} eingerichtet.
Für neue Ansätze und Ergebnisse, sowie Änderungen an Code und Dokumenten, wurden in \textit{GitHub} \textit{Branches} angelegt und über \textit{Pull-Requests} überprüft und diskutiert.

Die Abfolge der einzelnen Projektschritte orientierte sich an dem \textit{Data Science Life Cycle} (vgl. \cite[Abb. 2]{Stodden2020}).
Dieser wurde während der Anwendung der klassischen Methoden einmal durchlaufen.
Dies beinhaltet die wiederholte Durchführung von Schritten, wie \textit{Obtain Data} und \textit{Data Exploration} oder die parallele Ausführung von \textit{Data Preparation} und \textit{Model Estimation} bei der Durchführung der unterschiedlichden klassischen Verfahren.
Im Anschluss, bei der Anwendung der \textit{Deep Learning} Modelle, wurde gleichermaßen mehrfach über gewisse Schritte des \textit{Data Science Life Cycle} iteriert.

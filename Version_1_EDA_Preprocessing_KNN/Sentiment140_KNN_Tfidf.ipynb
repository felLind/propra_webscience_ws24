{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidf\n",
    "\n",
    "---\n",
    "\n",
    "**Datasets:**\n",
    "1. Dataset with apostrophe in regex and lemmatization\n",
    "    - sentiment140/sentiment140_lem_all_with_apostrophe.csv\n",
    "2. Dataset without apostrophe in regex and lemmatization\n",
    "    - => partially less token in tweet compared to dataset with apostrophe\n",
    "    - sentiment140/sentiment140_lem_all_no_apostrophe.csv\n",
    "3. Dataset with apostrophe in regex and stemming\n",
    "    - sentiment140/sentiment140_stem_all_with_apostrophe.csv\n",
    "4. Dataset without apostrophe in regex and stemming\n",
    "    - => partially less token in tweet compared to dataset with apostrophe\n",
    "    - sentiment140/sentiment140_stem_all_no_apostrophe.csv\n",
    "\n",
    "---\n",
    " For MAX_FEATURES = 5000 and 5% of the dataset, NGRAM_RANGE = (1,1)\n",
    "\n",
    "**GridSearch Best Parameters**: \n",
    "1. {'metric': 'minkowski', 'n_neighbors': 5, 'p': 2, 'weights': 'distance'}\n",
    "2. {'metric': 'minkowski', 'n_neighbors': 1, 'p': 2, 'weights': 'uniform'}\n",
    "3. {'metric': 'minkowski', 'n_neighbors': 1, 'p': 2, 'weights': 'uniform'}\n",
    "4. {'metric': 'minkowski', 'n_neighbors': 1, 'p': 2, 'weights': 'uniform'}\n",
    "\n",
    "\n",
    "\n",
    "**Accuracy best parameters from GridSearch**:\n",
    "\n",
    "|  | mit Apost. | ohne Apost. |\n",
    "|--|--|--|\n",
    "| Lem | 0.6134 | 0.6223 |\n",
    "| Stem | 0.6159 | 0.6196 |\n",
    "\n",
    "---\n",
    "\n",
    "1. Datensatz:\n",
    "\n",
    "**N_GRAM = (1,2)**:  \n",
    "**5% + MAX_FEATURES = 5000**\n",
    "- {'metric': 'minkowski', 'n_neighbors': 1, 'p': 2, 'weights': 'uniform'}\n",
    "    - test accuracy 0.61975\n",
    "    - train accuracy 0.985046875\n",
    "\n",
    "- {'metric': 'minkowski', 'n_neighbors': 5, 'p': 2, 'weights': 'distance'}\n",
    "    - test accuracy 0.6290625\n",
    "    - train accuracy 0.986953125\n",
    "\n",
    "**5% + MAX_FEATURES = 18000**\n",
    "- {'metric': 'minkowski', 'n_neighbors': 5, 'p': 2, 'weights': 'distance'}\n",
    "    - test accuracy 0.60025\n",
    "    - train accuracy 0.9915\n",
    "\n",
    "**10% + MAX_FEATURES = 18000**\n",
    "- {'metric': 'minkowski', 'n_neighbors': 5, 'p': 2, 'weights': 'distance'}\n",
    "    - test accuracy 0.62409375\n",
    "    - train accuracy 0.9905\n",
    "\n",
    "---\n",
    "\n",
    "Goal: train full dataset with best parameters from GridSearch and \n",
    "- MAX_FEATURES = unlimited => MemoryError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset with apostrophe in regex and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>aww that 's bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset ca n't update facebook texting might cry result school today also blah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>dived many time ball managed save 50 rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>behaving i 'm mad ca n't see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  \\\n",
       "0          0   \n",
       "1          0   \n",
       "2          0   \n",
       "3          0   \n",
       "4          0   \n",
       "\n",
       "                                                                          tweet  \n",
       "0                           aww that 's bummer shoulda got david carr third day  \n",
       "1  upset ca n't update facebook texting might cry result school today also blah  \n",
       "2                            dived many time ball managed save 50 rest go bound  \n",
       "3                                               whole body feel itchy like fire  \n",
       "4                                                  behaving i 'm mad ca n't see  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_NAME = 'sentiment140/sentiment140_lem_all_with_apostrophe.csv'\n",
    "ENCODING = 'latin-1'\n",
    "COLUMN_NAMES = ['sentiment', 'tweet']\n",
    "NROWS = 1600000\n",
    "\n",
    "df_with_apostrophe = pd.read_csv(DATA_NAME,\n",
    "                 encoding=ENCODING,\n",
    "                 header=None,\n",
    "                 names=COLUMN_NAMES,\n",
    "                 nrows=NROWS)\n",
    "\n",
    "df_with_apostrophe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% df sentiment\n",
      "0    80067\n",
      "1    79933\n",
      "Name: count, dtype: int64\n",
      "5% df sentiment\n",
      "0    40067\n",
      "1    39933\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# create smaller dataset\n",
    "length_of_df_w = df_with_apostrophe.shape[0]\n",
    "df_with_apostrophe_10 = df_with_apostrophe.iloc[int((length_of_df_w/2) - 80000):int((length_of_df_w/2) + 80000)]\n",
    "df_with_apostrophe_5 = df_with_apostrophe.iloc[int((length_of_df_w/2) - 40000):int((length_of_df_w/2) + 40000)]\n",
    "\n",
    "print('10% df', df_with_apostrophe_10.sentiment.value_counts())\n",
    "print('5% df', df_with_apostrophe_5.sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "USED_DF = df_with_apostrophe_10\n",
    "MAX_FEATURES = 18000\n",
    "NGRAM_RANGE = (1,2)\n",
    "TEST_SIZE = 0.2\n",
    "N_NEIGHBORS = 5\n",
    "METRIC = 'minkowski'\n",
    "P_VALUE = 2\n",
    "WEIGHTS = 'distance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                    USED_DF.tweet,\n",
    "                                    USED_DF.sentiment,\n",
    "                                    test_size=TEST_SIZE,\n",
    "                                    random_state=42\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_shape (128000, 18000)\n",
      "X_test_shape (32000, 18000)\n",
      "y_train_shape (128000,)\n",
      "y_test_shape (32000,)\n"
     ]
    }
   ],
   "source": [
    "# TFIDF model\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=MAX_FEATURES, ngram_range=NGRAM_RANGE)\n",
    "tfivectorizer = tfidf_vectorizer.fit(USED_DF.tweet)\n",
    "\n",
    "X_train_tfidf = tfivectorizer.transform(X_train)\n",
    "X_test_tfidf = tfivectorizer.transform(X_test)\n",
    "\n",
    "print(\"X_train_shape\", X_train_tfidf.toarray().shape)\n",
    "print(\"X_test_shape\", X_test_tfidf.toarray().shape)\n",
    "print(\"y_train_shape\", y_train.shape)\n",
    "print(\"y_test_shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report test\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.51      0.58     15891\n",
      "           1       0.60      0.73      0.66     16109\n",
      "\n",
      "    accuracy                           0.62     32000\n",
      "   macro avg       0.63      0.62      0.62     32000\n",
      "weighted avg       0.63      0.62      0.62     32000\n",
      "\n",
      "test accuracy 0.62409375\n",
      "train accuracy 0.9905\n"
     ]
    }
   ],
   "source": [
    "clf_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBORS, metric=METRIC, p=P_VALUE, weights=WEIGHTS).fit(X_train_tfidf, y_train)\n",
    "\n",
    "pred_X_train = clf_knn.predict(X_train_tfidf)\n",
    "pred_X_test = clf_knn.predict(X_test_tfidf)\n",
    "\n",
    "print('classification report test\\n', metrics.classification_report(y_test, pred_X_test))\n",
    "print('test accuracy', metrics.accuracy_score(y_test, pred_X_test))\n",
    "print('train accuracy', metrics.accuracy_score(y_train, pred_X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch for best KNN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "{'metric': 'minkowski', 'n_neighbors': 5, 'p': 2, 'weights': 'distance'}\n",
      "0.6134062499999999\n"
     ]
    }
   ],
   "source": [
    "PARAM_GRID = {'n_neighbors': [1, 5, 9, 13],\n",
    "              'p': [1, 2],\n",
    "              'weights': ('uniform', 'distance'),\n",
    "              'metric': ['minkowski']\n",
    "              }\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=KNeighborsClassifier(),\n",
    "                    param_grid=PARAM_GRID,\n",
    "                    scoring='accuracy',\n",
    "                    n_jobs=-1,\n",
    "                    refit=True,\n",
    "                    cv=5,\n",
    "                    verbose=4\n",
    "                    )\n",
    "\n",
    "grid.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Results\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report grid test\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.54      0.58      7991\n",
      "           1       0.60      0.70      0.65      8009\n",
      "\n",
      "    accuracy                           0.62     16000\n",
      "   macro avg       0.62      0.62      0.62     16000\n",
      "weighted avg       0.62      0.62      0.62     16000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict X_test for the best parameters\n",
    "pred_grid = grid.predict(X_test_tfidf)\n",
    "\n",
    "print('classification report grid test\\n', metrics.classification_report(y_test, pred_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset without apostrophe in regex and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['aww', 'bummer', 'shoulda', 'got', 'david', 'carr', 'third', 'day']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>['upset', 'update', 'facebook', 'texting', 'might', 'cry', 'result', 'school', 'today', 'also', 'blah']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>['dived', 'many', 'time', 'ball', 'managed', 'save', '50', 'rest', 'go', 'bound']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>['whole', 'body', 'feel', 'itchy', 'like', 'fire']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>['behaving', 'mad', 'see']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  \\\n",
       "0          0   \n",
       "1          0   \n",
       "2          0   \n",
       "3          0   \n",
       "4          0   \n",
       "\n",
       "                                                                                                     tweet  \n",
       "0                                     ['aww', 'bummer', 'shoulda', 'got', 'david', 'carr', 'third', 'day']  \n",
       "1  ['upset', 'update', 'facebook', 'texting', 'might', 'cry', 'result', 'school', 'today', 'also', 'blah']  \n",
       "2                        ['dived', 'many', 'time', 'ball', 'managed', 'save', '50', 'rest', 'go', 'bound']  \n",
       "3                                                       ['whole', 'body', 'feel', 'itchy', 'like', 'fire']  \n",
       "4                                                                               ['behaving', 'mad', 'see']  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_NAME = 'sentiment140/sentiment140_lem_all_no_apostrophe.csv'\n",
    "ENCODING = 'latin-1'\n",
    "COLUMN_NAMES = ['sentiment', 'tweet']\n",
    "NROWS = 1600000\n",
    "\n",
    "df_no_apostrophe = pd.read_csv(DATA_NAME,\n",
    "                                encoding=ENCODING,\n",
    "                                header=None,\n",
    "                                names=COLUMN_NAMES,\n",
    "                                nrows=NROWS\n",
    "                                )\n",
    "\n",
    "df_no_apostrophe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% df sentiment\n",
      "0    80081\n",
      "1    79919\n",
      "Name: count, dtype: int64\n",
      "5% df sentiment\n",
      "0    40081\n",
      "1    39919\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# create smaller dataset\n",
    "length_of_df_w = df_no_apostrophe.shape[0]\n",
    "df_no_apostrophe_10 = df_no_apostrophe.iloc[int((length_of_df_w/2) - 80000):int((length_of_df_w/2) + 80000)]\n",
    "df_no_apostrophe_5 = df_no_apostrophe.iloc[int((length_of_df_w/2) - 40000):int((length_of_df_w/2) + 40000)]\n",
    "\n",
    "print('10% df', df_no_apostrophe_10.sentiment.value_counts())\n",
    "print('5% df', df_no_apostrophe_5.sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "USED_DF = df_no_apostrophe_5\n",
    "MAX_FEATURES = 5000\n",
    "NGRAM_RANGE = (1,1)\n",
    "TEST_SIZE = 0.2\n",
    "N_NEIGHBORS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                    USED_DF.tweet,\n",
    "                                    USED_DF.sentiment,\n",
    "                                    test_size=TEST_SIZE,\n",
    "                                    random_state=42\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_shape (64000, 5000)\n",
      "X_test_shape (16000, 5000)\n",
      "y_train_shape (64000,)\n",
      "y_test_shape (16000,)\n"
     ]
    }
   ],
   "source": [
    "# TFIDF model\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=MAX_FEATURES, ngram_range=NGRAM_RANGE)\n",
    "tfivectorizer = tfidf_vectorizer.fit(USED_DF.tweet)\n",
    "\n",
    "X_train_tfidf = tfivectorizer.transform(X_train)\n",
    "X_test_tfidf = tfivectorizer.transform(X_test)\n",
    "\n",
    "print(\"X_train_shape\", X_train_tfidf.toarray().shape)\n",
    "print(\"X_test_shape\", X_test_tfidf.toarray().shape)\n",
    "print(\"y_train_shape\", y_train.shape)\n",
    "print(\"y_test_shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report test\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.79      0.68      7992\n",
      "           1       0.69      0.46      0.56      8008\n",
      "\n",
      "    accuracy                           0.63     16000\n",
      "   macro avg       0.65      0.63      0.62     16000\n",
      "weighted avg       0.65      0.63      0.62     16000\n",
      "\n",
      "test accuracy 0.6291875\n",
      "train accuracy 0.985890625\n"
     ]
    }
   ],
   "source": [
    "clf_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBORS).fit(X_train_tfidf, y_train)\n",
    "\n",
    "pred_X_train = clf_knn.predict(X_train_tfidf)\n",
    "pred_X_test = clf_knn.predict(X_test_tfidf)\n",
    "\n",
    "print('classification report test\\n', metrics.classification_report(y_test, pred_X_test))\n",
    "print('test accuracy', metrics.accuracy_score(y_test, pred_X_test))\n",
    "print('train accuracy', metrics.accuracy_score(y_train, pred_X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch for best KNN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "{'metric': 'minkowski', 'n_neighbors': 1, 'p': 2, 'weights': 'uniform'}\n",
      "0.6222656249999999\n"
     ]
    }
   ],
   "source": [
    "PARAM_GRID = {'n_neighbors': [1, 5, 9, 13],\n",
    "              'p': [1, 2],\n",
    "              'weights': ('uniform', 'distance'),\n",
    "              'metric': ['minkowski']\n",
    "              }\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=KNeighborsClassifier(),\n",
    "                    param_grid=PARAM_GRID,\n",
    "                    scoring='accuracy',\n",
    "                    n_jobs=-1,\n",
    "                    refit=True,\n",
    "                    cv=5,\n",
    "                    verbose=4\n",
    "                    )\n",
    "\n",
    "grid.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# results\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report grid test\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.79      0.68      7992\n",
      "           1       0.69      0.46      0.56      8008\n",
      "\n",
      "    accuracy                           0.63     16000\n",
      "   macro avg       0.65      0.63      0.62     16000\n",
      "weighted avg       0.65      0.63      0.62     16000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict X_test for the best parameters\n",
    "pred_grid = grid.predict(X_test_tfidf)\n",
    "\n",
    "print('classification report grid test\\n', metrics.classification_report(y_test, pred_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset with apostrophe in regex and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['aww', 'that', \"'s\", 'bummer', 'shoulda', 'got', 'david', 'carr', 'third', 'day']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>['upset', 'ca', \"n't\", 'updat', 'facebook', 'text', 'might', 'cri', 'result', 'school', 'today', 'also', 'blah']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>['dive', 'mani', 'time', 'ball', 'manag', 'save', '50', 'rest', 'go', 'bound']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>['whole', 'bodi', 'feel', 'itchi', 'like', 'fire']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>['behav', 'i', \"'m\", 'mad', 'ca', \"n't\", 'see']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  \\\n",
       "0          0   \n",
       "1          0   \n",
       "2          0   \n",
       "3          0   \n",
       "4          0   \n",
       "\n",
       "                                                                                                              tweet  \n",
       "0                                ['aww', 'that', \"'s\", 'bummer', 'shoulda', 'got', 'david', 'carr', 'third', 'day']  \n",
       "1  ['upset', 'ca', \"n't\", 'updat', 'facebook', 'text', 'might', 'cri', 'result', 'school', 'today', 'also', 'blah']  \n",
       "2                                    ['dive', 'mani', 'time', 'ball', 'manag', 'save', '50', 'rest', 'go', 'bound']  \n",
       "3                                                                ['whole', 'bodi', 'feel', 'itchi', 'like', 'fire']  \n",
       "4                                                                   ['behav', 'i', \"'m\", 'mad', 'ca', \"n't\", 'see']  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_NAME = 'sentiment140/sentiment140_stem_all_with_apostrophe.csv'\n",
    "ENCODING = 'latin-1'\n",
    "COLUMN_NAMES = ['sentiment', 'tweet']\n",
    "NROWS = 1600000\n",
    "\n",
    "df_with_apostrophe_stem = pd.read_csv(DATA_NAME,\n",
    "                 encoding=ENCODING,\n",
    "                 header=None,\n",
    "                 names=COLUMN_NAMES,\n",
    "                 nrows=NROWS)\n",
    "\n",
    "df_with_apostrophe_stem.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% df sentiment\n",
      "0    80067\n",
      "1    79933\n",
      "Name: count, dtype: int64\n",
      "5% df sentiment\n",
      "0    40067\n",
      "1    39933\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# create smaller dataset\n",
    "length_of_df_w = df_with_apostrophe_stem.shape[0]\n",
    "df_with_apostrophe_stem_10 = df_with_apostrophe_stem.iloc[int((length_of_df_w/2) - 80000):int((length_of_df_w/2) + 80000)]\n",
    "df_with_apostrophe_stem_5 = df_with_apostrophe_stem.iloc[int((length_of_df_w/2) - 40000):int((length_of_df_w/2) + 40000)]\n",
    "\n",
    "print('10% df', df_with_apostrophe_stem_10.sentiment.value_counts())\n",
    "print('5% df', df_with_apostrophe_stem_5.sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "USED_DF = df_with_apostrophe_stem_5\n",
    "MAX_FEATURES = 5000\n",
    "NGRAM_RANGE = (1,1)\n",
    "TEST_SIZE = 0.2\n",
    "N_NEIGHBORS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                    USED_DF.tweet,\n",
    "                                    USED_DF.sentiment,\n",
    "                                    test_size=TEST_SIZE,\n",
    "                                    random_state=42\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_shape (64000, 5000)\n",
      "X_test_shape (16000, 5000)\n",
      "y_train_shape (64000,)\n",
      "y_test_shape (16000,)\n"
     ]
    }
   ],
   "source": [
    "# TFIDF model\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=MAX_FEATURES, ngram_range=NGRAM_RANGE)\n",
    "tfivectorizer = tfidf_vectorizer.fit(USED_DF.tweet)\n",
    "\n",
    "X_train_tfidf = tfivectorizer.transform(X_train)\n",
    "X_test_tfidf = tfivectorizer.transform(X_test)\n",
    "\n",
    "print(\"X_train_shape\", X_train_tfidf.toarray().shape)\n",
    "print(\"X_test_shape\", X_test_tfidf.toarray().shape)\n",
    "print(\"y_train_shape\", y_train.shape)\n",
    "print(\"y_test_shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report test\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.80      0.68      7991\n",
      "           1       0.69      0.44      0.54      8009\n",
      "\n",
      "    accuracy                           0.62     16000\n",
      "   macro avg       0.64      0.62      0.61     16000\n",
      "weighted avg       0.64      0.62      0.61     16000\n",
      "\n",
      "test accuracy 0.6230625\n",
      "train accuracy 0.988078125\n"
     ]
    }
   ],
   "source": [
    "clf_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBORS).fit(X_train_tfidf, y_train)\n",
    "\n",
    "pred_X_train = clf_knn.predict(X_train_tfidf)\n",
    "pred_X_test = clf_knn.predict(X_test_tfidf)\n",
    "\n",
    "print('classification report test\\n', metrics.classification_report(y_test, pred_X_test))\n",
    "print('test accuracy', metrics.accuracy_score(y_test, pred_X_test))\n",
    "print('train accuracy', metrics.accuracy_score(y_train, pred_X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch for best KNN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "{'metric': 'minkowski', 'n_neighbors': 1, 'p': 2, 'weights': 'uniform'}\n",
      "0.615859375\n"
     ]
    }
   ],
   "source": [
    "PARAM_GRID = {'n_neighbors': [1, 5, 9, 13],\n",
    "              'p': [1, 2],\n",
    "              'weights': ('uniform', 'distance'),\n",
    "              'metric': ['minkowski']\n",
    "              }\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=KNeighborsClassifier(),\n",
    "                    param_grid=PARAM_GRID,\n",
    "                    scoring='accuracy',\n",
    "                    n_jobs=-1,\n",
    "                    refit=True,\n",
    "                    cv=5,\n",
    "                    verbose=4\n",
    "                    )\n",
    "\n",
    "grid.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Results\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report grid test\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.80      0.68      7991\n",
      "           1       0.69      0.44      0.54      8009\n",
      "\n",
      "    accuracy                           0.62     16000\n",
      "   macro avg       0.64      0.62      0.61     16000\n",
      "weighted avg       0.64      0.62      0.61     16000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict X_test for the best parameters\n",
    "pred_grid = grid.predict(X_test_tfidf)\n",
    "\n",
    "print('classification report grid test\\n', metrics.classification_report(y_test, pred_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset without apostrophe in regex and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['aww', 'bummer', 'shoulda', 'got', 'david', 'carr', 'third', 'day']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>['upset', 'updat', 'facebook', 'text', 'might', 'cri', 'result', 'school', 'today', 'also', 'blah']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>['dive', 'mani', 'time', 'ball', 'manag', 'save', '50', 'rest', 'go', 'bound']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>['whole', 'bodi', 'feel', 'itchi', 'like', 'fire']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>['behav', 'mad', 'see']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  \\\n",
       "0          0   \n",
       "1          0   \n",
       "2          0   \n",
       "3          0   \n",
       "4          0   \n",
       "\n",
       "                                                                                                 tweet  \n",
       "0                                 ['aww', 'bummer', 'shoulda', 'got', 'david', 'carr', 'third', 'day']  \n",
       "1  ['upset', 'updat', 'facebook', 'text', 'might', 'cri', 'result', 'school', 'today', 'also', 'blah']  \n",
       "2                       ['dive', 'mani', 'time', 'ball', 'manag', 'save', '50', 'rest', 'go', 'bound']  \n",
       "3                                                   ['whole', 'bodi', 'feel', 'itchi', 'like', 'fire']  \n",
       "4                                                                              ['behav', 'mad', 'see']  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_NAME = 'sentiment140/sentiment140_stem_all_no_apostrophe.csv'\n",
    "ENCODING = 'latin-1'\n",
    "COLUMN_NAMES = ['sentiment', 'tweet']\n",
    "NROWS = 1600000\n",
    "\n",
    "df_no_apostrophe_stem = pd.read_csv(DATA_NAME,\n",
    "                 encoding=ENCODING,\n",
    "                 header=None,\n",
    "                 names=COLUMN_NAMES,\n",
    "                 nrows=NROWS)\n",
    "\n",
    "df_no_apostrophe_stem.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% df sentiment\n",
      "0    80081\n",
      "1    79919\n",
      "Name: count, dtype: int64\n",
      "5% df sentiment\n",
      "0    40081\n",
      "1    39919\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# create smaller dataset\n",
    "length_of_df_w = df_no_apostrophe_stem.shape[0]\n",
    "df_no_apostrophe_stem_10 = df_no_apostrophe_stem.iloc[int((length_of_df_w/2) - 80000):int((length_of_df_w/2) + 80000)]\n",
    "df_no_apostrophe_stem_5 = df_no_apostrophe_stem.iloc[int((length_of_df_w/2) - 40000):int((length_of_df_w/2) + 40000)]\n",
    "\n",
    "print('10% df', df_no_apostrophe_stem_10.sentiment.value_counts())\n",
    "print('5% df', df_no_apostrophe_stem_5.sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "USED_DF = df_no_apostrophe_stem_5\n",
    "MAX_FEATURES = 5000\n",
    "NGRAM_RANGE = (1,1)\n",
    "TEST_SIZE = 0.2\n",
    "N_NEIGHBORS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                    USED_DF.tweet,\n",
    "                                    USED_DF.sentiment,\n",
    "                                    test_size=TEST_SIZE,\n",
    "                                    random_state=42\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_shape (64000, 5000)\n",
      "X_test_shape (16000, 5000)\n",
      "y_train_shape (64000,)\n",
      "y_test_shape (16000,)\n"
     ]
    }
   ],
   "source": [
    "# TFIDF model\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=MAX_FEATURES, ngram_range=NGRAM_RANGE)\n",
    "tfivectorizer = tfidf_vectorizer.fit(USED_DF.tweet)\n",
    "\n",
    "X_train_tfidf = tfivectorizer.transform(X_train)\n",
    "X_test_tfidf = tfivectorizer.transform(X_test)\n",
    "\n",
    "print(\"X_train_shape\", X_train_tfidf.toarray().shape)\n",
    "print(\"X_test_shape\", X_test_tfidf.toarray().shape)\n",
    "print(\"y_train_shape\", y_train.shape)\n",
    "print(\"y_test_shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report test\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.79      0.68      7992\n",
      "           1       0.68      0.46      0.55      8008\n",
      "\n",
      "    accuracy                           0.62     16000\n",
      "   macro avg       0.64      0.62      0.61     16000\n",
      "weighted avg       0.64      0.62      0.61     16000\n",
      "\n",
      "test accuracy 0.622375\n",
      "train accuracy 0.98734375\n"
     ]
    }
   ],
   "source": [
    "clf_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBORS).fit(X_train_tfidf, y_train)\n",
    "\n",
    "pred_X_train = clf_knn.predict(X_train_tfidf)\n",
    "pred_X_test = clf_knn.predict(X_test_tfidf)\n",
    "\n",
    "print('classification report test\\n', metrics.classification_report(y_test, pred_X_test))\n",
    "print('test accuracy', metrics.accuracy_score(y_test, pred_X_test))\n",
    "print('train accuracy', metrics.accuracy_score(y_train, pred_X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch for best KNN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "{'metric': 'minkowski', 'n_neighbors': 1, 'p': 2, 'weights': 'uniform'}\n",
      "0.61959375\n"
     ]
    }
   ],
   "source": [
    "PARAM_GRID = {'n_neighbors': [1, 5, 9, 13],\n",
    "              'p': [1, 2],\n",
    "              'weights': ('uniform', 'distance'),\n",
    "              'metric': ['minkowski']\n",
    "              }\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=KNeighborsClassifier(),\n",
    "                    param_grid=PARAM_GRID,\n",
    "                    scoring='accuracy',\n",
    "                    n_jobs=-1,\n",
    "                    refit=True,\n",
    "                    cv=5,\n",
    "                    verbose=4\n",
    "                    )\n",
    "\n",
    "grid.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Results\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report grid test\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.79      0.68      7992\n",
      "           1       0.68      0.46      0.55      8008\n",
      "\n",
      "    accuracy                           0.62     16000\n",
      "   macro avg       0.64      0.62      0.61     16000\n",
      "weighted avg       0.64      0.62      0.61     16000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict X_test for the best parameters\n",
    "pred_grid = grid.predict(X_test_tfidf)\n",
    "\n",
    "print('classification report grid test\\n', metrics.classification_report(y_test, pred_grid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
